{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "968b32ce",
   "metadata": {},
   "source": [
    "# perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f38c2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass        0\n",
      "Sex           0\n",
      "Age         177\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Fare          0\n",
      "Embarked      2\n",
      "dtype: int64\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the datasets\n",
    "df = pd.read_csv('../Datasets/titanic/train.csv')\n",
    "test_df = pd.read_csv(\"../Datasets/titanic/test.csv\")\n",
    "y_test_df = pd.read_csv(\"../Datasets/titanic/gender_submission.csv\")\n",
    "\n",
    "titanic_output_for_perceptron = df['Survived']\n",
    "df = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "test_df = test_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "print(df.isna().sum())\n",
    "\n",
    "\n",
    "titanic_input_for_perceptron = df\n",
    "titanic_input_for_perceptron[\"Age\"] = titanic_input_for_perceptron[\"Age\"].fillna(titanic_input_for_perceptron[\"Age\"].mean())\n",
    "test_df[\"Age\"] = test_df[\"Age\"].fillna(test_df[\"Age\"].mean())\n",
    "\n",
    "titanic_input_for_perceptron[\"Embarked\"] = titanic_input_for_perceptron[\"Embarked\"].fillna(titanic_input_for_perceptron[\"Embarked\"].mode()[0])\n",
    "test_df[\"Embarked\"] = test_df[\"Embarked\"].fillna(test_df[\"Embarked\"].mode()[0])\n",
    "\n",
    "\n",
    "test_df[\"Fare\"] = test_df[\"Fare\"].fillna(test_df[\"Fare\"].mean())\n",
    "\n",
    "# print(titanic_input_for_perceptron.isna().sum())\n",
    "print(test_df.isna().sum())\n",
    "\n",
    "titanic_input_for_perceptron[\"Sex\"] = titanic_input_for_perceptron['Sex'].map({\"male\":0, \"female\":1})\n",
    "test_df[\"Sex\"] = test_df['Sex'].map({\"male\":0, \"female\":1})\n",
    "\n",
    "en = OneHotEncoder()\n",
    "\n",
    "embarked_encoded = en.fit_transform(titanic_input_for_perceptron[['Embarked']])\n",
    "embarked_encoded_test_df = en.transform(test_df[['Embarked']])\n",
    "\n",
    "encoded_col_names = en.get_feature_names_out(['Embarked'])\n",
    "\n",
    "titanic_input_for_perceptron[encoded_col_names] = embarked_encoded.toarray()\n",
    "test_df[encoded_col_names] = embarked_encoded_test_df.toarray()\n",
    "\n",
    "titanic_input_for_perceptron.drop('Embarked', axis=1, inplace=True)\n",
    "test_df.drop('Embarked', axis=1, inplace=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "columns = titanic_input_for_perceptron.columns  # Save column names before scaling\n",
    "titanic_input_for_perceptron = pd.DataFrame(scaler.fit_transform(titanic_input_for_perceptron), columns=columns)\n",
    "test_df = pd.DataFrame(scaler.transform(test_df), columns=columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(titanic_input_for_perceptron[['Fare']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdeaf5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "\n",
    "learning_rate = 0.01\n",
    "# w = [] \n",
    "epochs = 10\n",
    "b = 0\n",
    "\n",
    "# titanic_input_for_perceptron['Bias'] = 1 \n",
    "# test_df['Bias'] = 1\n",
    "\n",
    "def calc_perceptron_output(x, w):\n",
    "    global b\n",
    "    res = b\n",
    "    for i, weight in enumerate(w):\n",
    "        res += weight * x[i]\n",
    "\n",
    "    return res\n",
    "\n",
    "def update_weights(y, ye, x, w):\n",
    "    learning_rate,b\n",
    "    for i, input_val in enumerate(x):\n",
    "        w[i] += learning_rate * input_val * (y - ye)\n",
    "    \n",
    "    b += learning_rate * (y - ye)\n",
    "    \n",
    "\n",
    "def train_perceptron(inputs, outputs, w=None, epochs=100, learning_rate=0.01):\n",
    "    # Initialize weights if not provided\n",
    "    if w is None:\n",
    "        w = [0] * len(inputs.columns)\n",
    "    \n",
    "    # Convert outputs to numpy array for clean comparison\n",
    "    y_true_values = outputs.values.ravel()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        correct = 0\n",
    "        for idx, row in inputs.iterrows():\n",
    "            x = row.values\n",
    "            y_true = y_true_values[idx]  # Now a scalar value\n",
    "            total = sum(w_i * x_i for w_i, x_i in zip(w, x))\n",
    "            y_pred = 1 if total > 0 else 0\n",
    "            \n",
    "            if y_pred != y_true:\n",
    "                # Update weights\n",
    "                for i in range(len(w)):\n",
    "                    w[i] += learning_rate * x[i] * (y_true - y_pred)\n",
    "        \n",
    "        # Optional: Print accuracy per epoch\n",
    "        if epoch % 10 == 0:\n",
    "            predictions = [1 if sum(w_i*x_i for w_i, x_i in zip(w, row)) > 0 else 0 \n",
    "                         for _, row in inputs.iterrows()]\n",
    "            acc = sum(p == y for p, y in zip(predictions, y_true_values)) / len(y_true_values)\n",
    "            print(f\"Epoch {epoch}: Accuracy = {acc:.2f}\")\n",
    "    \n",
    "    return w\n",
    "\n",
    "def predict_y(test_inputs, w):\n",
    "    pred_y_outputs = []\n",
    "\n",
    "    for idx, row in test_inputs.iterrows():\n",
    "        x = row.tolist()  \n",
    "        total = calc_perceptron_output(x, w)\n",
    "        y_pred = 1 if total > 0 else 0\n",
    "        pred_y_outputs.append(y_pred)\n",
    "\n",
    "    return pred_y_outputs\n",
    "\n",
    "\n",
    "# train_perceptron(titanic_input_for_perceptron, titanic_output_for_perceptron)\n",
    "\n",
    "\n",
    "#pred_y = predict_y(test_df)\n",
    "\n",
    "# print(accuracy_score(y_test_df['Survived'], pred_y))\n",
    "\n",
    "# print(y_test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eff300",
   "metadata": {},
   "source": [
    "# meta-features (combining features practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e1988",
   "metadata": {},
   "source": [
    "### using titanic dataset from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b10407c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass        0\n",
      "Sex           0\n",
      "Age           0\n",
      "SibSp         0\n",
      "Parch         0\n",
      "AgeGroup      0\n",
      "FareGroup     0\n",
      "Embarked_C    0\n",
      "Embarked_Q    0\n",
      "Embarked_S    0\n",
      "dtype: int64\n",
      "Index(['Pclass', 'Sex', 'Age', 'AgeGroup', 'FareGroup', 'Embarked_C',\n",
      "       'Embarked_Q', 'Embarked_S', 'Family_Solo', 'Family_Small',\n",
      "       'Family_Large'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18011/1614327377.py:45: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  x_train['Age'].fillna(x_train['Age'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# import standardScal\n",
    "\n",
    "dataset = pd.read_csv('../Datasets/titanic/train.csv')\n",
    "\n",
    "test_dataset = pd.read_csv('../Datasets/titanic/test.csv')\n",
    "\n",
    "\n",
    "x_train = dataset.drop('PassengerId', axis=1)\n",
    "\n",
    "y_train = x_train[['Survived']]\n",
    "\n",
    "x_train.drop('Name', axis=1, inplace=True)\n",
    "x_train.drop('Ticket', axis=1, inplace=True)\n",
    "x_train.drop('Cabin', axis=1, inplace=True)\n",
    "x_train.drop('Survived', axis=1, inplace=True)\n",
    "x_train['Sex'] = x_train['Sex'].map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "age_bins = [0, 12, 18, 65, 100]\n",
    "age_labels = ['child', 'teen', 'adult', 'senior']\n",
    "\n",
    "\n",
    "x_train['AgeGroup'] = pd.cut(x_train['Age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "x_train['AgeGroup'] = x_train['AgeGroup'].cat.codes\n",
    "\n",
    "fare_bins = [-1, 10, 50, 100, 1000]\n",
    "fare_labels = ['cheapest', 'economy', 'premium', 'luxury']\n",
    "\n",
    "x_train['FareGroup'] = pd.cut(x_train['Fare'], bins=fare_bins, labels=fare_labels)\n",
    "\n",
    "x_train['FareGroup'] = x_train['FareGroup'].cat.codes\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "embarked_encoded = encoder.fit_transform(x_train[['Embarked']])\n",
    "\n",
    "encoded_cols = encoder.get_feature_names_out(['Embarked'])\n",
    "x_train[encoded_cols] = embarked_encoded\n",
    "\n",
    "x_train.drop(['Embarked', 'Embarked_nan', 'Fare'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "x_train['Age'].fillna(x_train['Age'].mean(), inplace=True)\n",
    "print(x_train.isnull().sum())\n",
    "\n",
    "x_train['FamilySize'] = x_train['SibSp'] + x_train['Parch'] + 1  # +1 for self\n",
    "\n",
    "# Bin into categories\n",
    "x_train['FamilyType'] = pd.cut(x_train['FamilySize'], bins=[0, 1, 4, 11], labels=['Solo', 'Small', 'Large'])\n",
    "\n",
    "family_dummies = pd.get_dummies(x_train['FamilyType'], prefix='Family')\n",
    "x_train = pd.concat([x_train, family_dummies], axis=1)\n",
    "x_train.drop(['Parch', 'SibSp', 'FamilySize', 'FamilyType'], axis=1, inplace=True)\n",
    "\n",
    "print(x_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7443050d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pclass', 'Sex', 'Age', 'AgeGroup', 'FareGroup', 'Embarked_C',\n",
      "       'Embarked_Q', 'Embarked_S', 'Family_Solo', 'Family_Small',\n",
      "       'Family_Large'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18011/3085704054.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  x_test['Age'].fillna(x_train['Age'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "x_test = test_dataset.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "x_test['Sex'] = x_test['Sex'].map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "x_test['AgeGroup'] = pd.cut(x_test['Age'], bins=age_bins, labels=age_labels)\n",
    "x_test['AgeGroup'] = x_test['AgeGroup'].cat.codes\n",
    "\n",
    "x_test['Fare'] = x_test['Fare'].fillna(x_test['Fare'].median())  # Fill missing with median\n",
    "x_test['FareGroup'] = pd.cut(x_test['Fare'], bins=fare_bins, labels=fare_labels)\n",
    "\n",
    "x_test['Embarked'] = x_test['Embarked'].fillna(x_test['Embarked'].mode()[0])\n",
    "embarked_encoded_test = encoder.transform(x_test[['Embarked']])  # Use transform(), not fit_transform()\n",
    "x_test[encoded_cols] = embarked_encoded_test\n",
    "x_test.drop('Embarked', axis=1, inplace=True)\n",
    "\n",
    "x_test['FamilySize'] = x_test['SibSp'] + x_test['Parch'] + 1  # +1 for self\n",
    "x_test['FareGroup'] = x_test['FareGroup'].cat.codes\n",
    "\n",
    "# Bin into categories\n",
    "x_test['FamilyType'] = pd.cut(x_test['FamilySize'], bins=[0, 1, 4, 11], labels=['Solo', 'Small', 'Large'])\n",
    "family_dummies = pd.get_dummies(x_test['FamilyType'], prefix='Family')\n",
    "x_test = pd.concat([x_test, family_dummies], axis=1)\n",
    "\n",
    "x_test.drop(['Parch', 'SibSp', 'FamilySize', 'FamilyType'], axis=1, inplace=True)\n",
    "\n",
    "missing_cols = set(x_train.columns) - set(x_test.columns)\n",
    "for col in missing_cols:\n",
    "    x_test[col] = 0 \n",
    "\n",
    "x_test = x_test[x_train.columns] \n",
    "\n",
    "x_test['Age'].fillna(x_train['Age'].mean(), inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nTest Data Columns:\")\n",
    "print(x_test.columns)\n",
    "# print(\"\\nMissing Values in Test Data:\")\n",
    "# print(x_test.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "139bc2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Accuracy = 0.65\n",
      "Epoch 10: Accuracy = 0.66\n",
      "Epoch 20: Accuracy = 0.70\n",
      "Epoch 30: Accuracy = 0.75\n",
      "Epoch 40: Accuracy = 0.74\n",
      "Epoch 50: Accuracy = 0.75\n",
      "Epoch 60: Accuracy = 0.81\n",
      "Epoch 70: Accuracy = 0.81\n",
      "Epoch 80: Accuracy = 0.81\n",
      "Epoch 90: Accuracy = 0.78\n",
      "Epoch 100: Accuracy = 0.81\n",
      "Epoch 110: Accuracy = 0.82\n",
      "Epoch 120: Accuracy = 0.81\n",
      "Epoch 130: Accuracy = 0.82\n",
      "Epoch 140: Accuracy = 0.81\n",
      "Epoch 150: Accuracy = 0.81\n",
      "Epoch 160: Accuracy = 0.79\n",
      "Epoch 170: Accuracy = 0.81\n",
      "Epoch 180: Accuracy = 0.81\n",
      "Epoch 190: Accuracy = 0.82\n"
     ]
    }
   ],
   "source": [
    "w = train_perceptron(x_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47450826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9330143540669856"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict_y(x_test, w)\n",
    "predictions_train = predict_y(x_train, w)\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "\n",
    "y_test = pd.read_csv('../Datasets/titanic/gender_submission.csv')\n",
    "\n",
    "\n",
    "# print(y_train)\n",
    "accuracy_score(y_test['Survived'],predictions)\n",
    "accuracy_score(y_train['Survived'],predictions_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f132894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictions = predict_y(x_test, w) \n",
    "\n",
    "\n",
    "\n",
    "# 2. Create a DataFrame with IDs and predictions\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_dataset['PassengerId'],\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('../submissions/titanic_submission_v2_perceptron.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
